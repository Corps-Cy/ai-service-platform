# AI Service Platform - 生产环境部署配置
# 使用前请确保创建必要的目录：mkdir -p data uploads logs

version: '3.8'

services:
  # Redis服务 - 用于任务队列和缓存
  redis:
    image: redis:7-alpine
    container_name: ai-platform-redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - ai-platform
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # 后端API服务
  server:
    image: ghcr.io/corps-cy/ai-service-platform-server:latest
    container_name: ai-platform-server
    restart: unless-stopped
    ports:
      - "${SERVER_PORT:-3001}:3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
      - DATABASE_PATH=/app/data/database.sqlite
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - REDIS_CACHE_DB=1
      - FRONTEND_URL=${FRONTEND_URL:-http://localhost}
    volumes:
      - ./uploads:/app/uploads
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    env_file:
      - .env
    networks:
      - ai-platform
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # 前端Web服务
  client:
    image: ghcr.io/corps-cy/ai-service-platform-client:latest
    container_name: ai-platform-client
    restart: unless-stopped
    ports:
      - "${CLIENT_PORT:-80}:80"
    depends_on:
      - server
    networks:
      - ai-platform
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# 注意：前端使用相对路径 /api
# 需要在Nginx中配置 /api 代理到后端服务
# 参见 DEPLOYMENT.md 中的Nginx配置示例

# 数据卷 - Redis数据持久化
volumes:
  redis_data:
    driver: local

# 网络配置
networks:
  ai-platform:
    driver: bridge
